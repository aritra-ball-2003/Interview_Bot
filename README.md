# ğŸ§  AI Interview Bot â€” README

This project contains two core scripts that use NVIDIA's `AceInstruct-1.5B` language model to generate and continue interview conversations. It uses HuggingFace's `transformers` library and runs on GPU (`device_map="cuda"`).

---

## ğŸ“ File: `question_generation.py`

### ğŸ¯ Purpose
Generates **interview questions** based on a resume or input text using skills and projects mentioned.

### âš™ï¸ How It Works

1. **Model Setup**
   ```python
   model_name = "nvidia/AceInstruct-1.5B"
   tokenizer = AutoTokenizer.from_pretrained(model_name)
   model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype="float32", device_map="cuda")
   ```

2. **Prompt Template**
   ```
   Generate questions based on the below resume using Skills and Projects. Only return the questions, with no other data...
   ```

3. **Tokenization & Inference**
   - Applies chat template.
   - Sends input to GPU.
   - Generates up to 4096 tokens.

4. **Post-processing**
   - Removes bullet/number prefixes.
   - Filters out empty lines.
   - Adds an intro question:
     ```
     Hello! I'm excited to start our conversation. How would you like to introduce yourself?
     ```

5. **Returns**
   - A list of clean interview questions.

### âœ… Function Signature
```python
def generate_questions(prompt_text: str) -> list
```

---

## ğŸ“ File: `next_response.py`

### ğŸ¯ Purpose
Handles **follow-up interviewer dialogue** based on past conversation.

### ğŸŒ Flask Endpoint
```python
@next_response.route('/generate', methods=['POST'])
```

### ğŸ§© Input
```json
{
  "conversational_history": "..."
}
```

### âš™ï¸ How It Works

1. **Model Setup**
   - Loads the same `"nvidia/AceInstruct-1.5B"` model.

2. **Prompt Template**
   ```
   Continue the conversation based on the conversation given below, your role is "INTERVIEWER"...
   ```

3. **Tokenization & Inference**
   - Applies chat template.
   - Sends input to GPU.
   - Generates next response.

4. **Returns**
   - A plain text **next line** as the interviewer's response.

---

## ğŸ”„ Workflow Summary

| Step | File | Action |
|------|------|--------|
| ğŸ§¾ Resume Input | `question_generation.py` | Generates initial questions |
| ğŸ—£ï¸ Conversation Continuation | `next_response.py` | Generates next line for interviewer |

---

## ğŸ§ª Example Usage

### Generate Questions
```python
questions = generate_questions(resume_text)
```

### Generate Next Interviewer Line (Flask API)
```http
POST /generate
Content-Type: application/json

{
  "conversational_history": "Candidate: I am a software engineer with experience in NLP..."
}
```

---

## ğŸš€ Dependencies
- `transformers`
- `torch`
- `flask`

---

Let me know if you want a `requirements.txt`, Dockerfile, or front-end integration with this!
